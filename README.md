# ğŸš€ Peer-to-Peer Lending Risk Management

A complete, modular, end-to-end machine learning system for predicting **loan default risk** in peer-to-peer (P2P) lending platforms.  
The project includes **data cleaning**, **feature engineering**, **leakage-free preprocessing**, **model training**, and **evaluation** using Lending Clubâ€“style datasets (2007â€“2020).

---

## ğŸ“Œ Table of Contents

- ğŸ“„ Overview  
- â­ Features  
- ğŸ“ Project Structure  
- âš™ï¸ Installation  
- â–¶ï¸ Usage  
- ğŸ§  Pipeline Details  
- ğŸ“Š Outputs  
- ğŸ”® Future Improvements  
- ğŸ“œ License  

---

## ğŸ“„ Overview

This project builds a fully reproducible credit-risk modeling workflow.  
It provides a complete pipeline with:

- ğŸ§¹ **Robust data cleaning** & missing value handling  
- ğŸ“‰ **Hybrid IQR outlier capping** with summary reports  
- ğŸ§  **Feature engineering** for loan metadata, borrower traits, ratios, and time features  
- ğŸ§ª **Leakage-free ML preprocessing** (scaling, encoding inside pipelines)  
- ğŸ¤– **XGBoost model** with hyperparameter tuning  
- ğŸ“¦ **Train/Test parquet datasets**, **trained models**, and **logs**  
- ğŸ“Š **EDA notebooks** for insights  

Designed for: **fintech research**, **ML coursework**, and **risk analytics demos**.

---

## â­ Features

- ğŸ—‚ **Cleaned / engineered / processed datasets** stored as Parquet  
- ğŸ§® **Hybrid IQR capping** to handle extreme values  
- ğŸ” **PCA and non-PCA engineered features**  
- ğŸ”’ **Leakage-free ML pipeline**  
- ğŸ§  **XGBoost tuned model** with stored parameters  
- ğŸ“ **Detailed pipeline logging**  
- ğŸ““ **Jupyter notebooks for exploration**  

---

## ğŸ“ Project Structure

```plaintext
peer_to_peer_lending_risk_management/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Report/
|   â”œâ”€â”€ Project_Report_Peer_to_Peer_Lending_Risk_Management.pdf   
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Loan_status_2007-2020Q3.gzip
â”‚   â”œâ”€â”€ unemployment_rate_by_state.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ cleaned_data/
â”‚   â”‚   â”œâ”€â”€ cleaned_data.parquet
â”‚   â”‚   â”œâ”€â”€ hybrid_capping_summary.csv
â”‚   â”‚   â””â”€â”€ hybrid_capping_summary_final.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ feature_engineered/
â”‚   â”‚   â”œâ”€â”€ engineered_data.parquet
â”‚   â”‚   â””â”€â”€ engineered_data_no_pca.parquet
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ X_train_processed.parquet
â”‚   â”‚   â”œâ”€â”€ X_test_processed.parquet
â”‚   â”‚   â”œâ”€â”€ y_train.parquet
â”‚   â”‚   â””â”€â”€ y_test.parquet
â”‚   â”‚
â”‚   â””â”€â”€ raw_data/
â”‚       â””â”€â”€ data.parquet
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ pipeline.log
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ xgboost_tuned.pkl
â”‚   â””â”€â”€ xgboost_tuning_results.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploratory_data_analysis.ipynb
â”‚   â””â”€â”€ work.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_cleaning.py
â”‚   â”œâ”€â”€ data_feature_engineering.py
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ model.py
â”‚   â””â”€â”€ __init__.py
â”‚
â””â”€â”€ utils/
    â”œâ”€â”€ data_fetch.py
    â”œâ”€â”€ data_load.py
    â”œâ”€â”€ data_merge.py
    â”œâ”€â”€ hybrid_iqr_capping.py
    â”œâ”€â”€ logger.py
    â””â”€â”€ __init__.py
```

---

## âš™ï¸ Installation

1. **Clone this repo** and enter the directory:
    ```
    git clone https://github.com/DhruvParmar051/peer_to_peer_lending_risk_management.git
    cd peer_to_peer_lending_risk_management
    ```

2. **(Recommended) Create a virtual environment**:
    ```
    python -m venv venv
    source venv/bin/activate       # On Windows: venv\Scripts\activate
    ```

3. **Install requirements**:
    ```
    pip install -r requirements.txt
    ```

---

## â–¶ï¸ Running the Full Pipeline

The project includes a **`main.py` pipeline orchestrator** that automatically runs all machine-learning pipeline components in sequence:

- ğŸ§¹ **Data Cleaning**  
- ğŸ— **Feature Engineering**  
- âš™ï¸ **Preprocessing**  
- ğŸ¤– **Model Training (with tuning)**  

Running the entire ML workflow requires only:

```
python main.py
```
This executes the full credit-risk modeling pipeline from raw data to trained model.

---

## ğŸ” What `main.py` Does Internally

The orchestrator sequentially calls the following pipelines:

- clean_data_pipeline(...)  
- feature_engineering_pipeline(...)  
- data_preprocessing_pipeline(...)  
- model_pipeline(...)  

Each step automatically:
- Logs progress
- Saves intermediate datasets  
- Writes artifacts to the appropriate directories  

---

## â–¶ï¸ Running Individual Pipeline Steps (Optional)

If you prefer to run components separately:

### 1ï¸âƒ£ Data Cleaning
```
from src.data_cleaning import clean_data_pipeline  
clean_data_pipeline(input_path, output_dir)
```


### 2ï¸âƒ£ Feature Engineering
```
from src.data_feature_engineering import feature_engineering_pipeline  
feature_engineering_pipeline(cleaned_file, output_dir)
```

### 3ï¸âƒ£ Preprocessing
```
from src.data_preprocessing import data_preprocessing_pipeline  
data_preprocessing_pipeline(feature_file, output_dir)
```

### 4ï¸âƒ£ Model Training
```
from src.model import model_pipeline  
model_pipeline(processed_dir, model_dir)
```

---

## ğŸ§  Pipeline Details

### ğŸ§¹ Data Cleaning
- Missing value handling  
- Hybrid IQR outlier detection & capping  
- Summary report generation  
- Outputs: cleaned_data.parquet  

### ğŸ— Feature Engineering
- Numerical & categorical transformations  
- PCA / non-PCA feature variants  
- Outputs: engineered_data.parquet  

### âš™ï¸ Preprocessing
- Scalers and encoders inside Scikit-learn pipelines  
- Strictly leakage-free transformations  
- Outputs: train-test parquet files  

### ğŸ¤– Model Training
- XGBoost model with HalvingGridSearchCV tuning  
- Saves final trained model as .pkl  
- Saves tuning results as .csv  

---

## ğŸ“Š Outputs

| Folder | Description |
|--------|-------------|
| data/cleaned_data/ | Cleaned dataset + IQR capping summary |
| data/feature_engineered/ | PCA engineered datasets |
| data/processed/ | Train/test processed datasets |
| models/ | Final model + tuning results |
| logs/ | Full pipeline logs |

---

## ğŸ”® Future Improvements

- ğŸ§¾ Add SHAP explainability  
- ğŸ–¥ Build Streamlit dashboard for risk scoring  
- ğŸŒ Add FastAPI model-serving endpoint  
- ğŸ” Add model drift monitoring + alerts  
- ğŸ§¬ Add LightGBM, CatBoost, and ensemble models  
- âš™ï¸ Move pipeline to Airflow / Prefect  

---

## ğŸ“œ License

MIT License
