2025-11-16 19:41:41,357 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 19:41:41,359 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 19:41:41,359 - INFO - src.data_cleaning - Starting data cleaning pipeline.
2025-11-16 19:41:41,359 - INFO - utils.data_load - Loading dataset from D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\data\raw_data\data.parquet
2025-11-16 19:41:51,266 - INFO - utils.data_load - Loaded dataset: 2925493 rows, 145 columns
2025-11-16 19:42:13,998 - INFO - src.data_cleaning - Removed 0 duplicate rows.
2025-11-16 19:42:21,101 - INFO - src.data_cleaning - Dropped 22 columns: ['id', 'url', 'zip_code', 'emp_title', 'policy_code', 'application_type', 'pymnt_plan', 'hardship_flag', 'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_amnt', 'last_pymnt_d', 'last_credit_pull_d', 'issue_d', 'Unnamed_0']
2025-11-16 19:42:53,734 - INFO - src.data_cleaning - Cleaned data saved to D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\data\cleaned_data\cleaned_data.parquet
2025-11-16 19:42:53,739 - INFO - src.data_cleaning - Data cleaning pipeline completed.
2025-11-16 19:42:53,858 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 19:42:53,860 - INFO - src.data_feature_engineering - Starting feature engineering pipeline.
2025-11-16 19:42:53,862 - INFO - utils.data_load - Loading dataset from D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\data\cleaned_data\cleaned_data.parquet
2025-11-16 19:42:55,989 - INFO - utils.data_load - Loaded dataset: 2925493 rows, 85 columns
2025-11-16 19:42:55,990 - INFO - src.data_feature_engineering - Data loaded: (2925493, 85)
2025-11-16 19:42:55,990 - INFO - src.data_feature_engineering - Creating target variable 'is_default'.
2025-11-16 19:43:03,203 - INFO - src.data_feature_engineering - Feature engineered data saved: D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\data\feature_engineered\engineered_data.parquet
2025-11-16 19:43:03,269 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 19:43:03,270 - INFO - utils.data_load - Loading dataset from D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\data\feature_engineered\engineered_data.parquet
2025-11-16 19:43:04,171 - INFO - utils.data_load - Loaded dataset: 1860765 rows, 85 columns
2025-11-16 19:43:44,518 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-16 19:43:44,519 - INFO - src.model - Model pipeline started
2025-11-16 19:43:46,931 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-16 19:43:47,042 - INFO - src.model - Tuning XGBoost...
2025-11-16 19:49:19,459 - INFO - src.model - XGBoost best params: {'subsample': 1.0, 'reg_lambda': 3, 'reg_alpha': 0.01, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.03, 'gamma': 0.2, 'colsample_bytree': 0.6}
2025-11-16 19:49:19,905 - INFO - src.model - Tuning LightGBM...
2025-11-16 19:56:47,430 - INFO - src.model - LightGBM best params: {'subsample': 0.6, 'reg_lambda': 2, 'reg_alpha': 0.1, 'num_leaves': 64, 'n_estimators': 800, 'min_child_samples': 100, 'max_depth': 6, 'learning_rate': 0.05, 'colsample_bytree': 0.6}
2025-11-16 19:56:47,969 - INFO - src.model - Tuning CatBoost...
2025-11-16 20:18:02,101 - INFO - src.model - CatBoost best params: {'learning_rate': 0.03, 'l2_leaf_reg': 3, 'iterations': 800, 'depth': 4}
2025-11-16 20:24:05,779 - INFO - src.model - Stacking with full feature set and XGBoost meta-model
2025-11-16 20:24:15,125 - INFO - src.model - Selected F1 threshold: 0.3869
2025-11-16 20:24:21,333 - INFO - src.model - Final test metrics:
2025-11-16 20:24:21,333 - INFO - src.model - {'accuracy': 0.90928730925184, 'precision': 0.861079603562729, 'recall': 0.6378863849247892, 'f1': 0.73286646884273, 'roc_auc': 0.9509162675073324, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.92      0.98      0.95    299557\n           1       0.86      0.64      0.73     72596\n\n    accuracy                           0.91    372153\n   macro avg       0.89      0.81      0.84    372153\nweighted avg       0.91      0.91      0.90    372153\n', 'confusion_matrix': array([[292086,   7471],
       [ 26288,  46308]]), 'threshold': np.float64(0.3869230769230769)}
2025-11-16 20:24:22,549 - INFO - src.model - Model pipeline completed successfully.
2025-11-16 20:24:22,687 - INFO - __main__ - ===== FULL ML PIPELINE COMPLETED SUCCESSFULLY =====
2025-11-16 20:48:06,237 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 20:48:06,238 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 20:48:06,239 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 20:48:06,239 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 20:48:06,239 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-16 20:48:06,239 - INFO - src.model - Model pipeline started
2025-11-16 20:48:11,145 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-16 20:48:26,585 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 20:48:26,585 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 20:48:26,586 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 20:48:26,586 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 20:48:26,586 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-16 20:48:26,587 - INFO - src.model - Model pipeline started
2025-11-16 20:48:29,004 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-16 20:49:06,089 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 20:49:06,090 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 20:49:06,090 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 20:49:06,090 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 20:49:06,091 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-16 20:49:06,091 - INFO - src.model - Model pipeline started
2025-11-16 20:49:08,395 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-16 20:49:24,795 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 20:49:24,796 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 20:49:24,796 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 20:49:24,796 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 20:49:24,796 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-16 20:49:24,797 - INFO - src.model - Model pipeline started
2025-11-16 20:49:27,224 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-16 20:50:07,970 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 20:50:07,971 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 20:50:07,971 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 20:50:07,971 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 20:50:07,972 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-16 20:50:07,972 - INFO - src.model - Model pipeline started
2025-11-16 20:50:10,223 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-16 20:51:13,425 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 20:51:13,426 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 20:51:13,426 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 20:51:13,426 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 20:51:13,426 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-16 20:51:13,427 - INFO - src.model - Model pipeline started
2025-11-16 20:51:15,877 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-16 20:51:28,936 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 20:51:28,937 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 20:51:28,937 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 20:51:28,937 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 20:51:28,937 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-16 20:51:28,937 - INFO - src.model - Model pipeline started
2025-11-16 20:51:31,279 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-16 21:09:20,561 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 21:09:20,562 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 21:09:20,562 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 21:09:20,562 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 21:09:20,563 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-16 21:09:20,563 - INFO - src.model - Model pipeline started
2025-11-16 21:11:36,890 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 21:11:36,891 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 21:11:36,891 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 21:11:36,892 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 21:11:36,892 - INFO - utils.data_load - Loading dataset from D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\data\feature_engineered\engineered_data.parquet
2025-11-16 21:11:59,352 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 21:11:59,352 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 21:11:59,353 - INFO - src.data_cleaning - Starting data cleaning pipeline.
2025-11-16 21:11:59,353 - INFO - utils.data_load - Loading dataset from D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\data\raw_data\data.parquet
2025-11-16 21:12:59,890 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 21:12:59,891 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 21:12:59,891 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 21:12:59,892 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 21:12:59,892 - INFO - utils.data_load - Loading dataset from D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\data\feature_engineered\engineered_data.parquet
2025-11-16 21:13:03,110 - INFO - utils.data_load - Loaded dataset: 1860765 rows, 85 columns
2025-11-16 21:13:51,302 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-16 21:13:51,304 - INFO - src.model - Model pipeline started
2025-11-16 21:13:54,144 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-16 21:13:55,302 - INFO - src.model - Balance Bagging Classifier
2025-11-16 21:19:18,394 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 21:19:18,395 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 21:19:18,396 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 21:19:18,396 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 21:19:18,396 - INFO - utils.data_load - Loading dataset from D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\data\feature_engineered\engineered_data.parquet
2025-11-16 21:19:21,587 - INFO - utils.data_load - Loaded dataset: 1860765 rows, 85 columns
2025-11-16 21:19:43,700 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 21:19:43,701 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 21:19:43,701 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 21:19:43,701 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 21:19:43,701 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-16 21:19:43,732 - INFO - src.model - Model pipeline started
2025-11-16 21:19:47,464 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-16 21:19:47,886 - INFO - src.model - Balance Bagging Classifier
2025-11-16 21:23:07,676 - INFO - src.model - Stacking with full feature set and XGBoost meta-model
2025-11-16 21:23:22,973 - INFO - src.model - Selected recall-tuned threshold (F2): 0.5279
2025-11-16 21:23:22,974 - INFO - src.model - Selected F1 threshold: 0.5279
2025-11-16 21:24:58,732 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 21:24:58,733 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 21:24:58,733 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 21:24:58,733 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 21:24:58,733 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-16 21:24:58,733 - INFO - src.model - Model pipeline started
2025-11-16 21:25:03,775 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-16 21:25:04,092 - INFO - src.model - Balance Bagging Classifier
2025-11-16 21:28:30,057 - INFO - src.model - Stacking with full feature set and XGBoost meta-model
2025-11-16 21:28:45,645 - INFO - src.model - Selected recall-tuned threshold (F2): 0.5279
2025-11-16 21:28:45,645 - INFO - src.model - Selected F1 threshold: 0.5279
2025-11-16 21:28:51,792 - INFO - src.model - Final test metrics:
2025-11-16 21:28:51,792 - INFO - src.model - {'accuracy': 0.89359483868194, 'precision': 0.9110546378653113, 'recall': 0.5037054383161607, 'f1': 0.6487363948444554, 'roc_auc': 0.9528713234863131, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.89      0.99      0.94    299557\n           1       0.91      0.50      0.65     72596\n\n    accuracy                           0.89    372153\n   macro avg       0.90      0.75      0.79    372153\nweighted avg       0.90      0.89      0.88    372153\n', 'confusion_matrix': array([[295987,   3570],
       [ 36029,  36567]]), 'threshold': np.float64(0.5278595317725753)}
2025-11-16 21:28:52,762 - INFO - src.model - Model pipeline completed successfully.
2025-11-16 21:28:52,917 - INFO - __main__ - ===== FULL ML PIPELINE COMPLETED SUCCESSFULLY =====
2025-11-16 21:32:25,918 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 21:32:25,919 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 21:32:25,919 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 21:32:25,919 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 21:32:25,919 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-16 21:32:25,920 - INFO - src.model - Model pipeline started
2025-11-16 21:32:32,535 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-16 21:32:32,788 - INFO - src.model - Balance Bagging Classifier
2025-11-16 21:35:58,241 - INFO - src.model - Stacking with full feature set and XGBoost meta-model
2025-11-16 21:36:14,297 - INFO - src.model - Selected recall-tuned threshold (F2): 0.5279
2025-11-16 21:36:14,298 - INFO - src.model - Selected F1 threshold: 0.5279
2025-11-16 21:36:20,169 - INFO - src.model - Final test metrics:
2025-11-16 21:36:20,169 - INFO - src.model - {'accuracy': 0.89359483868194, 'precision': 0.9110546378653113, 'recall': 0.5037054383161607, 'f1': 0.6487363948444554, 'roc_auc': 0.9528713234863131, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.89      0.99      0.94    299557\n           1       0.91      0.50      0.65     72596\n\n    accuracy                           0.89    372153\n   macro avg       0.90      0.75      0.79    372153\nweighted avg       0.90      0.89      0.88    372153\n', 'confusion_matrix': array([[295987,   3570],
       [ 36029,  36567]]), 'threshold': np.float64(0.5278595317725753)}
2025-11-16 21:36:21,171 - INFO - src.model - Model pipeline completed successfully.
2025-11-16 21:36:21,336 - INFO - __main__ - ===== FULL ML PIPELINE COMPLETED SUCCESSFULLY =====
2025-11-16 21:40:00,214 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-16 21:40:00,215 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-16 21:40:00,216 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-16 21:40:00,216 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-16 21:40:00,216 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-16 21:40:00,217 - INFO - src.model - Model pipeline started
2025-11-16 21:40:05,656 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-16 21:40:05,968 - INFO - src.model - Balance Bagging Classifier
2025-11-16 21:44:20,020 - INFO - src.model - Stacking with full feature set and XGBoost meta-model
2025-11-16 21:44:39,185 - INFO - src.model - Selected recall-tuned threshold (F2): 0.5279
2025-11-16 21:44:39,185 - INFO - src.model - Selected F1 threshold: 0.5279
2025-11-16 21:44:48,034 - INFO - src.model - Final test metrics:
2025-11-16 21:44:48,035 - INFO - src.model - {'accuracy': 0.8821130019105046, 'precision': 0.6395371431902532, 'recall': 0.9067303983690561, 'f1': 0.7500484269778147, 'roc_auc': 0.953841867074986, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.97      0.88      0.92    299557\n           1       0.64      0.91      0.75     72596\n\n    accuracy                           0.88    372153\n   macro avg       0.81      0.89      0.84    372153\nweighted avg       0.91      0.88      0.89    372153\n', 'confusion_matrix': array([[262456,  37101],
       [  6771,  65825]]), 'threshold': np.float64(0.5278595317725753)}
2025-11-16 21:44:49,034 - INFO - src.model - Model pipeline completed successfully.
2025-11-16 21:44:49,160 - INFO - __main__ - ===== FULL ML PIPELINE COMPLETED SUCCESSFULLY =====
2025-11-30 17:22:51,618 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-30 17:22:51,629 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-30 17:22:51,630 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-30 17:22:51,630 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-30 17:22:51,630 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-30 17:22:51,631 - INFO - src.model - Model pipeline started
2025-11-30 17:22:58,682 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-30 17:22:58,763 - INFO - src.model - Tuning XGBoost...
2025-11-30 17:23:35,964 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-30 17:23:35,965 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-30 17:23:35,965 - INFO - src.data_cleaning - Starting data cleaning pipeline.
2025-11-30 17:23:35,965 - INFO - utils.data_load - Loading dataset from D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\data\raw_data\data.parquet
2025-11-30 17:23:46,240 - INFO - utils.data_load - Loaded dataset: 2925493 rows, 145 columns
2025-11-30 17:24:12,059 - INFO - src.data_cleaning - Removed 0 duplicate rows.
2025-11-30 17:24:17,701 - INFO - src.data_cleaning - Dropped 22 columns: ['id', 'url', 'zip_code', 'emp_title', 'policy_code', 'application_type', 'pymnt_plan', 'hardship_flag', 'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_amnt', 'last_pymnt_d', 'last_credit_pull_d', 'issue_d', 'Unnamed_0']
2025-11-30 17:24:47,189 - INFO - src.data_cleaning - Cleaned data saved to D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\data\cleaned_data\cleaned_data.parquet
2025-11-30 17:24:47,199 - INFO - src.data_cleaning - Data cleaning pipeline completed.
2025-11-30 17:24:47,364 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-30 17:24:47,366 - INFO - src.data_feature_engineering - Starting feature engineering pipeline.
2025-11-30 17:24:47,369 - INFO - utils.data_load - Loading dataset from D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\data\cleaned_data\cleaned_data.parquet
2025-11-30 17:24:49,655 - INFO - utils.data_load - Loaded dataset: 2925493 rows, 85 columns
2025-11-30 17:24:49,657 - INFO - src.data_feature_engineering - Data loaded: (2925493, 85)
2025-11-30 17:24:49,657 - INFO - src.data_feature_engineering - Creating target variable 'is_default'.
2025-11-30 17:24:56,842 - INFO - src.data_feature_engineering - Feature engineered data saved: D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\data\feature_engineered\engineered_data.parquet
2025-11-30 17:24:56,910 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-30 17:24:56,912 - INFO - utils.data_load - Loading dataset from D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\data\feature_engineered\engineered_data.parquet
2025-11-30 17:24:57,798 - INFO - utils.data_load - Loaded dataset: 1860765 rows, 85 columns
2025-11-30 17:25:40,227 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-30 17:25:40,228 - INFO - src.model - Model pipeline started
2025-11-30 17:25:42,661 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-30 17:25:42,825 - INFO - src.model - Tuning XGBoost...
2025-11-30 17:28:28,931 - INFO - src.model - XGBoost best params: {'subsample': 1.0, 'reg_lambda': 2, 'reg_alpha': 0.1, 'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 4, 'learning_rate': 0.03, 'gamma': 0, 'colsample_bytree': 0.6}
2025-11-30 17:28:29,344 - INFO - src.model - Tuning LightGBM...
2025-11-30 17:32:24,404 - INFO - src.model - LightGBM best params: {'subsample': 0.6, 'reg_lambda': 2, 'reg_alpha': 0.1, 'num_leaves': 64, 'n_estimators': 800, 'min_child_samples': 100, 'max_depth': 6, 'learning_rate': 0.05, 'colsample_bytree': 0.6}
2025-11-30 17:32:24,865 - INFO - src.model - Tuning CatBoost...
2025-11-30 17:35:20,550 - INFO - src.model - CatBoost best params: {'learning_rate': 0.01, 'l2_leaf_reg': 3, 'iterations': 300, 'depth': 6}
2025-11-30 17:35:20,763 - INFO - src.model - Balance Bagging Classifier
2025-11-30 17:38:01,620 - INFO - src.model - Stacking with full feature set and XGBoost meta-model
2025-11-30 17:38:25,020 - INFO - src.model - Selected recall-tuned threshold (F2): 0.5082
2025-11-30 17:38:25,020 - INFO - src.model - Selected F1 threshold: 0.5082
2025-11-30 17:38:34,443 - INFO - src.model - Final test metrics:
2025-11-30 17:38:34,444 - INFO - src.model - {'accuracy': 0.8805491289872713, 'precision': 0.6347358140069326, 'recall': 0.9131081602292137, 'f1': 0.7488900186409083, 'roc_auc': 0.9545061925762405, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.98      0.87      0.92    299557\n           1       0.63      0.91      0.75     72596\n\n    accuracy                           0.88    372153\n   macro avg       0.81      0.89      0.84    372153\nweighted avg       0.91      0.88      0.89    372153\n', 'confusion_matrix': array([[261411,  38146],
       [  6308,  66288]]), 'threshold': np.float64(0.5081939799331103)}
2025-11-30 17:38:35,362 - INFO - src.model - Model pipeline completed successfully.
2025-11-30 17:38:35,639 - INFO - __main__ - ===== FULL ML PIPELINE COMPLETED SUCCESSFULLY =====
2025-11-30 17:49:15,183 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-30 17:49:15,184 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-30 17:49:15,184 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-30 17:49:15,185 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-30 17:49:15,185 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-30 17:49:15,185 - INFO - src.model - Model pipeline started
2025-11-30 17:49:20,061 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-30 17:51:20,875 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-30 17:51:20,876 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-30 17:51:20,876 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-30 17:51:20,876 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-30 17:51:20,877 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-30 17:51:20,877 - INFO - src.model - Model pipeline started
2025-11-30 17:51:24,372 - INFO - src.model - Using scale_pos_weight=4.126
2025-11-30 18:05:11,167 - INFO - src.model - Model pipeline completed successfully.
2025-11-30 18:05:11,525 - INFO - __main__ - ===== FULL ML PIPELINE COMPLETED SUCCESSFULLY =====
2025-11-30 18:07:08,287 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-30 18:07:08,288 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-30 18:07:08,288 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-30 18:07:08,288 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-30 18:07:08,289 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-30 18:07:08,289 - INFO - model_pipeline - Model pipeline started
2025-11-30 18:07:14,514 - INFO - model_pipeline - Using scale_pos_weight=4.126
2025-11-30 18:07:14,515 - INFO - utils.tuning - Starting RandomizedSearchCV for XGBoost
2025-11-30 18:09:22,192 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-30 18:09:22,201 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-30 18:09:22,202 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-30 18:09:22,202 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-30 18:09:22,202 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-30 18:09:22,202 - INFO - model_pipeline - Model pipeline started
2025-11-30 18:09:28,463 - INFO - model_pipeline - Using scale_pos_weight=4.126
2025-11-30 18:09:28,476 - INFO - utils.tuning - Starting RandomizedSearchCV for XGBoost
2025-11-30 18:10:59,397 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-30 18:10:59,420 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-30 18:10:59,421 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-30 18:10:59,422 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-30 18:10:59,422 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-30 18:10:59,423 - INFO - model_pipeline - Model pipeline started
2025-11-30 18:11:05,295 - INFO - model_pipeline - Using scale_pos_weight=4.126
2025-11-30 18:11:05,306 - INFO - utils.tuning - Starting RandomizedSearchCV for XGBoost
2025-11-30 18:12:43,416 - INFO - __main__ - ===== STARTING FULL ML PIPELINE =====
2025-11-30 18:12:43,417 - INFO - __main__ - STEP 1: Running Data Cleaning Pipeline
2025-11-30 18:12:43,418 - INFO - __main__ - STEP 2: Running Feature Engineering Pipeline
2025-11-30 18:12:43,418 - INFO - __main__ - STEP 3: Running Data Preprocessing Pipeline
2025-11-30 18:12:43,419 - INFO - __main__ - STEP 4: Running Model Tuning Pipeline
2025-11-30 18:12:43,419 - INFO - model_pipeline - Model pipeline started
2025-11-30 18:12:46,625 - INFO - model_pipeline - Using scale_pos_weight=4.126
2025-11-30 18:12:46,626 - INFO - utils.tuning - Starting RandomizedSearchCV for XGBoost
2025-11-30 18:16:41,810 - INFO - utils.tuning - XGBoost best params: {'subsample': 0.7, 'reg_lambda': 1, 'reg_alpha': 0, 'n_estimators': 300, 'min_child_weight': 1, 'max_depth': 8, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 0.8}
2025-11-30 18:16:42,239 - INFO - utils.tuning - Saved RandomizedSearchCV result to D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\models\best_XGBoost.pkl
2025-11-30 18:16:42,240 - INFO - utils.tuning - Starting RandomizedSearchCV for LightGBM
2025-11-30 18:19:13,071 - INFO - utils.tuning - LightGBM best params: {'subsample': 0.6, 'reg_lambda': 1, 'reg_alpha': 0.1, 'num_leaves': 64, 'n_estimators': 800, 'min_child_samples': 100, 'max_depth': 6, 'learning_rate': 0.03, 'colsample_bytree': 0.6}
2025-11-30 18:19:13,567 - INFO - utils.tuning - Saved RandomizedSearchCV result to D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\models\best_LightGBM.pkl
2025-11-30 18:19:13,568 - INFO - utils.tuning - Starting RandomizedSearchCV for CatBoost
2025-11-30 18:21:22,702 - INFO - utils.tuning - CatBoost best params: {'learning_rate': 0.01, 'l2_leaf_reg': 3, 'iterations': 300, 'depth': 6}
2025-11-30 18:21:22,729 - INFO - utils.tuning - Saved RandomizedSearchCV result to D:\DAU\SEM 1\DS605 - Fundamentals of Machine Learning\peer_to_peer_lending_risk_management\models\best_CatBoost.pkl
2025-11-30 18:21:23,176 - INFO - model_pipeline - Loaded pretrained tuned models from ./models/
2025-11-30 18:23:37,348 - INFO - model_pipeline - Balanced bagging fitted on full training data
2025-11-30 18:23:37,350 - INFO - utils.stacking - Training meta-model on validation set of shape (223292, 100)
2025-11-30 18:23:37,352 - INFO - utils.stacking - Building stacking features for data of shape (223292, 100)
2025-11-30 18:23:45,557 - INFO - utils.stacking - Tuning threshold using F2 with 300 steps
2025-11-30 18:24:01,095 - INFO - utils.stacking - Tuned threshold = 0.5147 with F2 = 0.8458
2025-11-30 18:24:01,096 - INFO - utils.stacking - Meta-model trained. Best threshold: 0.5147
2025-11-30 18:24:01,098 - INFO - utils.stacking - Building stacking features for data of shape (372153, 100)
2025-11-30 18:24:08,878 - INFO - utils.stacking - Building stacking features for data of shape (372153, 100)
2025-11-30 18:24:15,696 - INFO - utils.evaluation - Evaluating model: Stacked_Meta_Model
2025-11-30 18:24:17,184 - INFO - utils.evaluation - Stacked_Meta_Model metrics: AUC=0.9569 F1=0.7512 Precision=0.6336 Recall=0.9224
2025-11-30 18:24:17,187 - INFO - model_pipeline - Final test metrics: {'accuracy': 0.88080440034072, 'precision': 0.6335853305452791, 'recall': 0.9224061931786876, 'f1': 0.7511905095773621, 'roc_auc': 0.9568670250573089, 'threshold': np.float64(0.5147491638795987)}
2025-11-30 18:24:18,067 - INFO - model_pipeline - Model pipeline completed successfully.
2025-11-30 18:24:18,426 - INFO - __main__ - ===== FULL ML PIPELINE COMPLETED SUCCESSFULLY =====
